from runpod.serverless.utils import rp_upload
import runpod
import os
import sys
import time
import json
import requests
import base64
import subprocess
import threading
import uuid
from pathlib import Path
from PIL import Image
import io
import shutil
import boto3
from datetime import timedelta


ENDPOINT_URL = os.environ["BUCKET_ENDPOINT_URL"]   
BUCKET_NAME  = os.environ["BUCKET_NAME"]          
REGION       = os.getenv("AWS_REGION", "EU-RO-1")

s3 = boto3.client(
    "s3",
    region_name           = REGION,
    endpoint_url          = ENDPOINT_URL,
    aws_access_key_id     = os.environ["BUCKET_ACCESS_KEY_ID"],
    aws_secret_access_key = os.environ["BUCKET_SECRET_ACCESS_KEY"],
)

# Configuraci√≥n
WORKSPACE_PATH = "/runpod-volume"
COMFYUI_PATH = f"{WORKSPACE_PATH}/ComfyUI"
WORKFLOW_PATH = "/app/workflow.json"
COMFYUI_URL = "http://localhost:8188"

# üî• NUEVO: Configuraci√≥n para RunPod output. Rutas absolutas para evitar problemas con cambios de directorio
OUTPUT_DIR = Path(f"{COMFYUI_PATH}/output")           # Donde ComfyUI guarda
RP_OUTPUT_DIR = Path("/runpod-volume/output_objects")   # <- ra√≠z del contenedor üî• Network volume
RP_OUTPUT_DIR.mkdir(exist_ok=True, parents=True)


TARGET_NODE = "94"          # mant√©nlo como string. Nodo del que sacamos el v√≠deo en extract_outpu...

def upload_video_hybrid(src: Path, job_id: str) -> str:
    """
    Sube el v√≠deo `src` al bucket definido en las variables de entorno y
    devuelve una URL lista para que el usuario la descargue.

    Requisitos de entorno (todos ya existen; solo comprueba el ENDPOINT):
        BUCKET_ACCESS_KEY_ID
        BUCKET_SECRET_ACCESS_KEY
        BUCKET_NAME
        BUCKET_ENDPOINT_URL = https://<BUCKET_NAME>.s3api-eu-ro-1.runpod.io
                              # ‚Üê incluye SIEMPRE el nombre del bucket
                              #    tal y como aconseja la gu√≠a de RunPod.
    """
    
    
    date_prefix = datetime.utcnow().strftime("%m-%d")      # ¬´06-25¬ª, etc.
    from botocore.config import Config

    # 1Ô∏è‚É£  Subida sencilla con el helper oficial.
    upload_url = rp_upload.upload_file_to_bucket(
+        file_name     = src.name,
+        file_location = str(src),
+        bucket_name   = BUCKET_NAME,    # ‚Üê SIEMPRE tu volumen: z41252jtk8
+        prefix        = date_prefix,    # carpeta dentro del bucket
+        extra_args    = {
+            "ContentType": "video/mp4",
+            "ACL": "public-read"        # qu√≠talo si mantienes el bucket privado
+        }
+    )

    # Si el helper ya devuelve una URL p√∫blica, la devolvemos tal cual.
    if isinstance(upload_url, str) and upload_url.startswith("http"):
        return upload_url

    # 2Ô∏è‚É£  Caso bucket privado ‚Üí generamos URL presignada de 24 h.
    s3_client = boto3.client(
        "s3",
        region_name=os.getenv("AWS_REGION", "EU-RO-1"),
        endpoint_url=os.environ["BUCKET_ENDPOINT_URL"],
        aws_access_key_id=os.environ["BUCKET_ACCESS_KEY_ID"],
        aws_secret_access_key=os.environ["BUCKET_SECRET_ACCESS_KEY"],
        config=Config(signature_version="s3v4")
    )

    key = f"{date_prefix}/{src.name}"                      # misma carpeta
    presigned_url = s3_client.generate_presigned_url(
        "get_object",
        Params={"Bucket": BUCKET_NAME, "Key": key},
        ExpiresIn=int(timedelta(days=1).total_seconds())   # 24 h
    )
    return presigned_url
    
def upload_video_hybridold(src: Path, job_id: str) -> str:
    """Funci√≥n corregida usando las funciones correctas para serverless"""
    
    print(f"üöÄ Subiendo {src.name} ({src.stat().st_size / 1_048_576:.2f} MB)")
    
    # M√âTODO 1: upload_image (solo 2 par√°metros)
    print("üîÑ Intentando rp_upload.upload_image...")
    try:
        upload_result = rp_upload.upload_image(job_id, str(src))
        
        print(f"üîç upload_image resultado: {upload_result}")
        print(f"üîç Tipo: {type(upload_result)}")
        
        if upload_result:
            if isinstance(upload_result, str) and upload_result.startswith('http'):
                print(f"‚úÖ upload_image exitoso: {upload_result}")
                return upload_result
            else:
                # Puede devolver solo el nombre del archivo o path relativo
                result_str = str(upload_result)
                print(f"üîç upload_image devolvi√≥ string: {result_str}")
                
                # Si contiene una URL, extraerla
                if 'http' in result_str:
                    print(f"‚úÖ URL encontrada en resultado: {result_str}")
                    return result_str
                else:
                    print(f"‚ö†Ô∏è upload_image devolvi√≥: {result_str}")
        
    except Exception as e:
        print(f"‚ùå upload_image fall√≥: {e}")
        import traceback
        print(f"‚ùå Traceback: {traceback.format_exc()}")
    
    # M√âTODO 2: upload_in_memory_object 
    print("üîÑ Intentando upload_in_memory_object...")
    try:
        with open(src, 'rb') as f:
            file_data = f.read()
        
        # Seg√∫n los logs anteriores, esta funci√≥n existe
        upload_result = rp_upload.upload_in_memory_object(
            job_id,
            file_data,
            src.name
        )
        
        print(f"üîç upload_in_memory_object resultado: {upload_result}")
        
        if upload_result and isinstance(upload_result, str) and upload_result.startswith('http'):
            print(f"‚úÖ upload_in_memory_object exitoso: {upload_result}")
            return upload_result
            
    except Exception as e:
        print(f"‚ùå upload_in_memory_object fall√≥: {e}")
    
    # M√âTODO 3: Fallback local
    print("üîÑ Fallback: archivo local...")
    try:
        output_dir = Path("/runpod-volume/outputs")
        output_dir.mkdir(exist_ok=True, parents=True)
        
        timestamp = int(time.time())
        output_file = output_dir / f"video_{job_id}_{timestamp}_{src.name}"
        shutil.copy2(src, output_file)
        
        if output_file.exists():
            print(f"üìÅ Video copiado exitosamente: {output_file}")
            return f"/outputs/{output_file.name}"
    
    except Exception as e:
        print(f"‚ùå Fallback fall√≥: {e}")
    
    return str(src)

def debug_rp_upload_detailed():
    """Debug detallado de rp_upload"""
    try:
        print("üîç === DEBUGGING rp_upload ===")
        
        # Mostrar funciones disponibles
        functions = [attr for attr in dir(rp_upload) if not attr.startswith('_')]
        print(f"Funciones disponibles: {functions}")
        
        # Inspeccionar upload_file_to_bucket
        if hasattr(rp_upload, 'upload_file_to_bucket'):
            import inspect
            sig = inspect.signature(rp_upload.upload_file_to_bucket)
            print(f"upload_file_to_bucket signature: {sig}")
        
        # Inspeccionar bucket_upload
        if hasattr(rp_upload, 'bucket_upload'):
            import inspect
            sig = inspect.signature(rp_upload.bucket_upload)
            print(f"bucket_upload signature: {sig}")
            
        print("üîç === END DEBUG ===")
        
    except Exception as e:
        print(f"‚ùå Error en debug: {e}")



def upload_video_boto3_fixed(src: Path, job_id: str) -> str:
    """boto3 con configuraci√≥n corregida como funci√≥n separada"""
    from botocore.config import Config
    
    config = Config(signature_version='s3v4')
    s3_client = boto3.client(
        's3',
        region_name=REGION,
        endpoint_url=ENDPOINT_URL,
        aws_access_key_id=os.environ["BUCKET_ACCESS_KEY_ID"],
        aws_secret_access_key=os.environ["BUCKET_SECRET_ACCESS_KEY"],
        config=config
    )
    
    key = f"{job_id}/{src.name}"
    
    with open(src, "rb") as fh:
        s3_client.put_object(
            Bucket=BUCKET_NAME,
            Key=key,
            Body=fh,
            ContentType="video/mp4"
        )
    
    return s3_client.generate_presigned_url(
        'get_object',
        Params={'Bucket': BUCKET_NAME, 'Key': key},
        ExpiresIn=int(timedelta(days=7).total_seconds())
    )


def upload_video(src: Path, job_id: str) -> str:
    from botocore.config import Config
    
    # Configuraci√≥n espec√≠fica para RunPod S3
    config = Config(
        signature_version='s3v4',
        region_name=REGION,
        retries={'max_attempts': 4, 'mode': 'adaptive'}
    )
    
    # Recrear el cliente S3 con la configuraci√≥n correcta
    s3_client = boto3.client(
        "s3",
        region_name=REGION,
        endpoint_url=ENDPOINT_URL,
        aws_access_key_id=os.environ["BUCKET_ACCESS_KEY_ID"],
        aws_secret_access_key=os.environ["BUCKET_SECRET_ACCESS_KEY"],
        config=config  # ‚Üê Esta es la clave
    )
    
    key = f"{job_id}/{src.name}"
    
    # 1. Subida del archivo
    with open(src, "rb") as fh:
        s3_client.put_object(
            Bucket=BUCKET_NAME,
            Key=key,
            Body=fh,
            ContentType="video/mp4"
        )
    
    # 2. Generar URL presignada con la configuraci√≥n correcta
    try:
        presigned_url = s3_client.generate_presigned_url(
            'get_object',
            Params={
                'Bucket': BUCKET_NAME,
                'Key': key
            },
            ExpiresIn=int(timedelta(days=7).total_seconds())
        )
        
        print(f"‚úÖ URL presignada generada: {presigned_url}")
        return presigned_url
        
    except Exception as e:
        print(f"‚ùå Error generando URL presignada: {e}")
        raise Exception(f"Failed to generate presigned URL: {e}")

def save_base64_image(base64_string, filename):
    """Guardar imagen base64 en el sistema de archivos con procesamiento PIL"""
    try:
        # Remover el prefijo data:image si existe
        if ',' in base64_string:
            base64_string = base64_string.split(',')[1]

        # A√±adir padding si es necesario para evitar el error "Incorrect padding"
        missing_padding = len(base64_string) % 4
        if missing_padding:
            base64_string += '=' * (4 - missing_padding)

        # Decodificar base64
        image_data = base64.b64decode(base64_string)
                
        # Cargar imagen desde bytes
        image = Image.open(io.BytesIO(image_data))
        
        # Manejar diferentes modos de color correctamente
        if image.mode == 'RGBA':
            # Crear fondo blanco para transparencias
            background = Image.new('RGB', image.size, (255, 255, 255))
            background.paste(image, mask=image.split()[3])  # Alpha channel
            image = background
        elif image.mode == 'P':
            # Paleta de colores
            image = image.convert('RGB')
        elif image.mode not in ('RGB', 'L'):
            image = image.convert('RGB')
        
        # Crear directorio input si no existe
        input_dir = f"{COMFYUI_PATH}/input"
        os.makedirs(input_dir, exist_ok=True)
        
        # Guardar imagen con m√°xima calidad
        image_path = f"{input_dir}/{filename}"
        image.save(image_path, 'PNG', optimize=False, compress_level=0)
        
        print(f"‚úÖ Image saved: {image_path} (Mode: {image.mode}, Size: {image.size})")
        return filename
        
    except Exception as e:
        print(f"‚ùå Error saving image: {e}")
        raise Exception(f"Failed to save input image: {e}")


def download_image_from_url(image_url):
    """Descargar imagen desde URL"""
    try:
        
        print(f"üì• Downloading image from: {image_url}")
        
        # Descargar imagen
        response = requests.get(image_url, timeout=30)
        response.raise_for_status()
        
        # Procesar con PIL
        image = Image.open(io.BytesIO(response.content))
        
        # Manejar diferentes modos de color
        if image.mode == 'RGBA':
            background = Image.new('RGB', image.size, (255, 255, 255))
            background.paste(image, mask=image.split()[3])
            image = background
        elif image.mode == 'P':
            image = image.convert('RGB')
        elif image.mode not in ('RGB', 'L'):
            image = image.convert('RGB')
        
        # Guardar
        input_dir = f"{COMFYUI_PATH}/input"
        os.makedirs(input_dir, exist_ok=True)
        
        timestamp = int(time.time() * 1000000)
        filename = f"input_{timestamp}.png"
        image_path = f"{input_dir}/{filename}"
        
        image.save(image_path, 'PNG', optimize=False, compress_level=0)
        
        print(f"‚úÖ Image downloaded and saved: {image_path} (Mode: {image.mode}, Size: {image.size})")
        return filename  # ‚úÖ Devolver solo filename para consistencia
        
    except Exception as e:
        print(f"‚ùå Error downloading image: {e}")
        raise Exception(f"Failed to download image: {e}")

def process_image_input(image_input):
    """Procesar imagen desde cualquier formato"""
    try:
        if isinstance(image_input, str):
            if image_input.startswith(("http://", "https://")):
                # URL
                print("üîó Processing image from URL")
                return download_image_from_url(image_input)
            elif image_input.startswith("data:image") or len(image_input) > 100:
                # Base64
                print("üìÑ Processing image from Base64")
                timestamp = int(time.time() * 1000000)
                filename = f"input_{timestamp}.png"
                return save_base64_image(image_input, filename)
            else:
                raise ValueError(f"Invalid image string format: {image_input[:50]}...")
        else:
            raise ValueError(f"Unknown image input format: {type(image_input)}")
            
    except Exception as e:
        print(f"‚ùå Error processing image: {e}")
        raise Exception(f"Failed to process image: {e}")


def modify_workflow(workflow: dict,
                    image_filename: str,
                    prompt: str,
                    negative_prompt: str,
                    width: int = 832,
                    height: int = 480) -> dict:
    """
    Modifica el workflow con los par√°metros del usuario
    """
    import time
    
    # Generar seed √∫nico
    unique_seed = int(time.time() * 1000000) % 2147483647  # M√°s variaci√≥n
    print(f"üé≤ Generated unique seed: {unique_seed}")
    
    # Crear una copia del workflow para no modificar el original
    modified_workflow = workflow.copy()
    
    # NODO 294: LoadImage - Actualizar imagen de entrada
    if "294" in modified_workflow:
        if "inputs" in modified_workflow["294"]:
            modified_workflow["294"]["inputs"]["image"] = image_filename
            print(f"‚úÖ Updated LoadImage (294) with image: {image_filename}")
        else:
            print(f"‚ùå Node 294 missing inputs section")
    else:
        print(f"‚ùå Node 294 (LoadImage) not found in workflow")
    
    # NODO 243: Prompt positivo
    if "243" in modified_workflow:
        if "inputs" in modified_workflow["243"]:
            modified_workflow["243"]["inputs"]["text"] = prompt
            print(f"‚úÖ Updated positive prompt (243): {prompt[:50]}...")
        else:
            print(f"‚ùå Node 243 missing inputs section")
    else:
        print(f"‚ùå Node 243 (positive prompt) not found in workflow")
    
    # NODO 244: Prompt negativo
    if "244" in modified_workflow:
        if "inputs" in modified_workflow["244"]:
            modified_workflow["244"]["inputs"]["text"] = negative_prompt
            print(f"‚úÖ Updated negative prompt (244): {negative_prompt[:50]}...")
        else:
            print(f"‚ùå Node 244 missing inputs section")
    else:
        print(f"‚ùå Node 244 (negative prompt) not found in workflow")
    
    # NODO 259: KSampler - Actualizar seed
    if "259" in modified_workflow:
        if "inputs" in modified_workflow["259"]:
            modified_workflow["259"]["inputs"]["seed"] = unique_seed
            print(f"‚úÖ Updated KSampler (259) seed: {unique_seed}")
        else:
            print(f"‚ùå Node 259 missing inputs section")
    else:
        print(f"‚ùå Node 259 (KSampler) not found in workflow")

    # NODO 236: WanImageToVideo - width y height
    if "236" in modified_workflow and "inputs" in modified_workflow["236"]:
        modified_workflow["236"]["inputs"]["width"] = width
        modified_workflow["236"]["inputs"]["height"] = height
        print(f"‚úÖ Updated WanImageToVideo dimensions: {width}x{height}")
    
    # Verificar que los cambios se aplicaron
    print("üîç Verification:")
    if "294" in modified_workflow and "inputs" in modified_workflow["294"]:
        print(f"  - Image: {modified_workflow['294']['inputs'].get('image', 'NOT SET')}")
    if "243" in modified_workflow and "inputs" in modified_workflow["243"]:
        print(f"  - Positive: {modified_workflow['243']['inputs'].get('text', 'NOT SET')[:30]}...")
    if "244" in modified_workflow and "inputs" in modified_workflow["244"]:
        print(f"  - Negative: {modified_workflow['244']['inputs'].get('text', 'NOT SET')[:30]}...")
    if "259" in modified_workflow and "inputs" in modified_workflow["259"]:
        print(f"  - Seed: {modified_workflow['259']['inputs'].get('seed', 'NOT SET')}")
    
    return modified_workflow


# FUNCI√ìN DE DEBUG
def debug_workflow_connections(workflow: dict):
    """Debug para entender las conexiones actuales del workflow"""
    print("üîç === WORKFLOW DEBUG ===")
    
    # Verificar nodos cr√≠ticos
    critical_nodes = ["231", "232", "233", "302", "243", "244", "236", "290"]
    
    for node_id in critical_nodes:
        if node_id in workflow:
            node = workflow[node_id]
            class_type = node.get("class_type", "Unknown")
            inputs = node.get("inputs", {})
            print(f"üîç Node {node_id} ({class_type}):")
            for input_name, input_value in inputs.items():
                print(f"    {input_name}: {input_value}")
        else:
            print(f"‚ùå Node {node_id} NOT FOUND in workflow")
    
    # Verificar espec√≠ficamente los nodos Anything Everywhere
    anything_everywhere_nodes = ["280", "281", "282"]
    print("\nüîç === ANYTHING EVERYWHERE NODES ===")
    for node_id in anything_everywhere_nodes:
        if node_id in workflow:
            node = workflow[node_id]
            print(f"üîç Node {node_id}: {node}")
        else:
            print(f"‚ùå Anything Everywhere node {node_id} NOT FOUND")
    
    print("üîç === END DEBUG ===\n")


def execute_workflow(job_id, workflow):
    """Ejecutar workflow en ComfyUI y esperar resultado"""
    try:
        # Generar ID √∫nico para este prompt
        prompt_id = str(uuid.uuid4())
        
        # Preparar payload para ComfyUI API
        payload = {
            "prompt": workflow,
            "client_id": prompt_id
        }
        
        print(f"üöÄ Sending workflow to ComfyUI with ID: {prompt_id}")
        
        # Enviar workflow a ComfyUI
        response = requests.post(f"{COMFYUI_URL}/prompt", json=payload)
        response.raise_for_status()
        
        result = response.json()
        prompt_id = result["prompt_id"]
        print(f"‚úÖ Workflow submitted successfully, prompt_id: {prompt_id}")
        
        # Polling para esperar a que termine
        print("‚è≥ Waiting for workflow execution...")
        max_wait = 900  # antes era 5 minutos m√°ximo ahora es 15
        start_time = time.time()
        
        while time.time() - start_time < max_wait:
            # Verificar estado
            history_response = requests.get(f"{COMFYUI_URL}/history/{prompt_id}")
            
            if history_response.status_code == 200:
                history = history_response.json()
                
                if prompt_id in history:
                    execution_data = history[prompt_id]
                    
                    # Verificar si termin√≥
                    if "outputs" in execution_data:
                        print("‚úÖ Workflow execution completed!")
                        # Pasa el job_id a extract_output_files
                        return extract_output_files(job_id, execution_data["outputs"]) # <-- A√ëADE job_id
                    
                    # Verificar si hay error
                    elif "status" in execution_data:
                        status = execution_data["status"]
                        if status.get("status_str") == "error":
                            error_msg = status.get("messages", ["Unknown error"])
                            raise Exception(f"Workflow execution failed: {error_msg}")
            
            # Esperar antes del siguiente check
            time.sleep(5)
            
            # Log de progreso cada 30 segundos
            if int(time.time() - start_time) % 30 == 0:
                elapsed = int(time.time() - start_time)
                print(f"‚è≥ Still waiting... ({elapsed}s elapsed)")
        
        raise Exception("Workflow execution timeout after 15 minutes")
        
    except Exception as e:
        print(f"‚ùå Error executing workflow: {e}")
        raise Exception(f"Failed to execute workflow: {e}")



def extract_output_files(job_id, outputs): # <-- Acepta job_id
    """Usar rp_upload para obtener URLs descargables y devolver la URL del video."""
    # Debug de rp_upload al inicio
    debug_rp_upload_detailed()
    
    for node_id, node_output in outputs.items():
        if str(node_id) != TARGET_NODE:  # TARGET_NODE es '94'
            continue

        # La salida puede estar en 'videos' o 'gifs', s√© flexible
        for key in ("videos", "gifs"):
            if key not in node_output:
                continue

            video_info = node_output[key][0]
            # La ruta completa del archivo generado en el contenedor
            src = Path(video_info["fullpath"])

            if not src.exists():
                raise FileNotFoundError(f"El archivo de video no se encontr√≥ en la ruta: {src}")

            # Sube el archivo a RunPod y obt√©n la URL segura
            try:
                print(f"üöÄ Subiendo {src.name} al bucket con el job_id: {job_id}")
                
                # --- Usando la llamada a la funci√≥n 100% correcta ---
                video_url = upload_video_hybrid(src, job_id)
                # ----------------------------------------------------
                
                print(f"‚úÖ Video subido exitosamente. URL: {video_url}")
                
                return {
                    "type": "video",
                    "url": video_url,
                    "filename": src.name,
                    "original_path": str(src),
                    "file_size": f"{round(src.stat().st_size / 1_048_576, 2)} MB",
                    "node_id": TARGET_NODE
                }
                
            except Exception as e:
                print(f"‚ùå Error al subir el video con rp_upload: {e}")
                # Si la subida falla, es un error cr√≠tico
                raise RuntimeError(f"No se pudo subir el archivo de video: {e}")

    # Si no se encuentra el nodo de salida, lanza un error
    raise RuntimeError(f"No se encontr√≥ ninguna salida de video en el nodo esperado ({TARGET_NODE})")


def file_to_base64(file_path):
    """Convertir archivo a base64"""
    try:
        with open(file_path, 'rb') as f:
            file_data = f.read()
            base64_data = base64.b64encode(file_data).decode('utf-8')
            return base64_data
    except Exception as e:
        print(f"‚ùå Error converting file to base64: {e}")
        return None

def generate_video(job_id, input_image, prompt, negative_prompt="", width=832, height=480):
    """Generar video usando el workflow completo"""
    try:
        print("üé¨ Starting video generation...")
        
       # 1. Procesar imagen de entrada (h√≠brido)
        saved_filename = process_image_input(input_image)
        
        # 2. Cargar y modificar workflow
        print("üìù Loading and modifying workflow...")
        with open(WORKFLOW_PATH, 'r') as f:
            workflow = json.load(f)

        # üî• NUEVO: Debug inicial
        print("üîç BEFORE modifications:")
     #   debug_workflow_connections(workflow)
        
        modified_workflow = modify_workflow(workflow, saved_filename, prompt, negative_prompt, width, height)

        # üî• NUEVO: Debug despu√©s de modify_workflow
        print("üîç AFTER modify_workflow:")
      #  debug_workflow_connections(modified_workflow)

                  
        # 3. Ejecutar workflow y obtener el diccionario con la URL
        output_data = execute_workflow(job_id, modified_workflow) # <-- A√ëADE job_id
        
        if not output_data or "url" not in output_data:
            raise Exception("No se gener√≥ la URL del video de salida")
        
        print(f"‚úÖ Generaci√≥n de video completada. URL: {output_data['url']}")
        
        # 4. Devuelve el resultado incluyendo el diccionario completo de salida
        return {
            "status": "success",
            "output": output_data  # Devuelve directamente el objeto con la URL
        }
        
    except Exception as e:
        print(f"‚ùå La generaci√≥n de video fall√≥: {e}")
        return {
            "status": "error",
            "message": str(e)
        }

def get_file_size(file_path):
    """Obtener tama√±o del archivo en MB"""
    try:
        size_bytes = os.path.getsize(file_path)
        size_mb = round(size_bytes / (1024 * 1024), 2)
        return f"{size_mb} MB"
    except:
        return "Unknown"


def check_models():
    """Verificar que los modelos est√©n disponibles en el network volume"""
    required_models = {
        "diffusion_models": ["wan2.1_i2v_480p_14B_bf16.safetensors"],
        "text_encoders": ["umt5_xxl_fp8_e4m3fn_scaled.safetensors"],
        "vae": ["wan_2.1_vae.safetensors"],
        "clip_vision": ["clip_vision_h.safetensors"],
        "upscale_models": ["4xLSDIR.pth"]
    }
    
    for model_type, models in required_models.items():
        model_path = f"{COMFYUI_PATH}/models/{model_type}"
        if not os.path.exists(model_path):
            raise Exception(f"Model directory not found: {model_path}")
        
        for model in models:
            model_file = f"{model_path}/{model}"
            if not os.path.exists(model_file):
                raise Exception(f"Required model not found: {model_file}")
    
    print("‚úÖ All required models found!")
    return True

def start_comfyui():
    """Iniciar ComfyUI server o verificar si ya est√° ejecut√°ndose"""
    # üî• NUEVO: Verificar si ComfyUI ya est√° ejecut√°ndose
    try:
        response = requests.get(f"{COMFYUI_URL}/history", timeout=5)
        if response.status_code == 200:
            print("‚úÖ ComfyUI already running! Reusing existing instance.")
            return True
    except Exception:
        print("üîß ComfyUI not running, starting new instance...")
        
     # üî• SOLUCI√ìN ELEGANTE: Verificar/crear symlink solo si no existe
    symlink_path = "/ComfyUI"
    if not (os.path.exists(symlink_path) or os.path.islink(symlink_path)):
        os.symlink(COMFYUI_PATH, symlink_path)
        print(f"üîó Symlink creado: {symlink_path} ‚Üí {COMFYUI_PATH}")
    else:
        print(f"‚ÑπÔ∏è {symlink_path} ya existe: se reutiliza (link o directorio).")
    
    print(f"üìÇ Changing directory to: {COMFYUI_PATH}")
    os.chdir(COMFYUI_PATH)
    
    # Verificar que main.py existe
    if not os.path.exists("main.py"):
        raise Exception(f"‚ùå main.py not found in {COMFYUI_PATH}")
    
    print("üîß Starting ComfyUI process...")
    cmd = [
        "python", "main.py", 
        "--listen", "0.0.0.0",
        "--port", "8188"
    ]
    
    print(f"üöÄ Command: {' '.join(cmd)}")
    
    # Iniciar ComfyUI con logs visibles
    process = subprocess.Popen(
        cmd, 
        stdout=subprocess.PIPE, 
        stderr=subprocess.STDOUT,
        text=True,
        bufsize=1
    )
    
    # Mostrar logs en tiempo real
    def show_logs():
        for line in process.stdout:
            print(f"ComfyUI: {line.strip()}")
    
    thread = threading.Thread(target=show_logs, daemon=True)
    thread.start()
    
    # Esperar a que ComfyUI est√© listo
    print("‚è≥ Waiting for ComfyUI to be ready...")
    for i in range(300):  # 5 minutos
        try:
            response = requests.get(f"{COMFYUI_URL}/history", timeout=5)
            if response.status_code == 200:
                print("‚úÖ ComfyUI is ready!")
                return True
        except Exception as e:
            if i % 30 == 0:  # Log cada 30 segundos
                print(f"‚è≥ Still waiting... ({i//60}m {i%60}s) - {e}")
        time.sleep(1)
    
    print("‚ùå ComfyUI logs:")
    if process.poll() is not None:
        print(f"Process exited with code: {process.returncode}")
    
    raise Exception("‚ùå ComfyUI failed to start within 5 minutes")

def handler(event):
    """Handler principal de RunPod"""
    try:
        print("üöÄ Starting WAN 2.1 I2V serverless handler...")
        
        # Verificar modelos
        print("üîç Checking models...")
        check_models()
        
        # Iniciar ComfyUI
        print("‚ö° Starting ComfyUI...")
        start_comfyui()
        
        # Obtener inputs
        job_input = event.get("input", {})
        job_id = event.get("id") # <-- A√ëADE ESTA L√çNEA
        
        if not job_input:
            return { 
                "message": "No input provided"
            }
        
        # Generar video
        result = generate_video(
            job_id, # <-- A√ëADE ESTE ARGUMENTO
            job_input.get("image", ""),
            job_input.get("prompt", ""),
            job_input.get("negative_prompt", ""),
            job_input.get("width", 832),      # Valor por defecto
            job_input.get("height", 480)      # Valor por defecto
        )
        
        return result
        
    except Exception as e:
        return {
            "message": str(e)
        }

print("üöÄ Starting RunPod Serverless handler...")
runpod.serverless.start({"handler": handler})
